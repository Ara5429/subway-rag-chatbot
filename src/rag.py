from langchain.docstore.document import Document
from naver_search import parse_station_exit # â† ìƒˆë¡œ ì¶”ê°€# â† ìƒˆë¡œ ì¶”ê°€
from naver_search import build_naver_blog_context # â† ìƒˆë¡œ ì¶”ê°€
from naver_search import build_naver_places_context # â† ìƒˆë¡œ ì¶”ê°€
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
import retriever as retriever


# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini",temperature=0)

# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages, docs):
    response = retriever.document_chain.stream({
        "messages": messages,
        "context": docs
    })
    for chunk in response:
        yield chunk

# Streamlit ì•±
st.title("ğŸ’¬ ì§€í•˜ì² ì— ëŒ€í•œ ëª¨ë“ ê²ƒ")
# ë„¤ì´ë²„ ì˜µì…˜
use_naver = st.sidebar.checkbox("ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì‚¬ìš©", value=True)
naver_days = st.sidebar.slider("ë¸”ë¡œê·¸ ìµœì‹ ì„±(ì¼)", min_value=7, max_value=60, step=7, value=30)


# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì§€í•˜ì²  ì‚¬ìš©ì, ìœ ë… ì‹œê°ì¥ì• ì¸í•œí…Œ ë„ì›€ì„ ì£¼ëŠ” ì§€í•˜ì²  ì „ë¬¸ ìœ„ì¹˜ ì „ë¬¸ê°€ì•¼. "),  
        AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ì§€í•˜ì² ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ì €ëŠ” ì§€í•˜ì²  ìœ„ì¹˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ğŸ˜Š"),
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt) # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt)) # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    # 1. ì§ˆì˜ ì¦ê°•
    augmented_query = retriever.query_augmentation_chain.invoke({
        "messages": st.session_state["messages"],
        "query": prompt,
    })
    # ë¬¸ìì—´ ì •ê·œí™” 
    try:
        aug_q = augmented_query.strip()
    except Exception:
        if isinstance(augmented_query, dict):
            aug_q = augmented_query.get("query") or ""
        else:
            aug_q = str(augmented_query or "")
    query_for_retrieval = (f"{prompt}\n{aug_q}").strip()
    print("augmented_query(type):", type(augmented_query).__name__)
    print("query_for_retrieval:", query_for_retrieval)
    
    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    print("ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰")
    try:
        docs = retriever.retriever.invoke(query_for_retrieval)
    except AttributeError:
        docs = retriever.retriever.get_relevant_documents(query_for_retrieval)
    
    #ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì¶”ê°€
    if use_naver:
        try:
            # âš ï¸ aug_qì—ì„œ ì—­/ì¶œêµ¬ ìš°ì„  íŒŒì‹± (ì—†ìœ¼ë©´ promptë¡œ ë³´ì¡°)
            station, exit_no = parse_station_exit(aug_q)
            if not station:
                station, exit_no = parse_station_exit(prompt)

        # ì¹´í…Œê³ ë¦¬ ì¶”ì •ë„ aug_q ê¸°ì¤€
            keyword = "í–„ë²„ê±°" if any(k in aug_q for k in ["í–„ë²„ê±°", "ë²„ê±°"]) else "ë§›ì§‘"

        # ë„¤ì´ë²„ ë¡œì»¬(ì¥ì†Œ) â†’ ì¶œêµ¬/ì—­ í‚¤ì›Œë“œê°€ ë°˜ì˜ëœ aug_q ê¸°ë°˜
            local_ctx = build_naver_places_context(station, exit_no, keyword=keyword, top_k=5)

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ â†’ aug_q ìì²´ë¡œ ê²€ìƒ‰ + ì—­ëª… í¬í•¨ í•„í„°
            blog_ctx  = build_naver_blog_context(aug_q, station=station, days=naver_days, max_items=6)

            local_doc = Document(page_content=local_ctx, metadata={"source": "ë„¤ì´ë²„_ë¡œì»¬"})
            blog_doc  = Document(page_content=blog_ctx,  metadata={"source": "ë„¤ì´ë²„_ë¸”ë¡œê·¸"})

        # ì›¹ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì•ì— ë‘¬ì„œ ëª¨ë¸ì´ ìš°ì„  ë³´ê²Œ í•¨
            docs = [local_doc, blog_doc] + list(docs)
        except Exception as e:
            st.warning(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            
    # RAG ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
    for doc in docs:
        print('---------------')
        print(doc)   
        with st.expander(f"**ë¬¸ì„œ:** {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}"):
            # íŒŒì¼ëª…ê³¼ í˜ì´ì§€ ì •ë³´ í‘œì‹œ
            st.write(f"**page:**{doc.metadata.get('page', '')}")
            st.write(doc.page_content)
    print("===============")

    with st.spinner(f"AIê°€ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤... '{augmented_query}'"):
        try:
            response = get_ai_response(st.session_state["messages"], docs)
            result = st.chat_message("assistant").write_stream(response)
        except Exception:
            # í´ë°±: docsë¥¼ ë¬¸ìì—´ë¡œ ë³‘í•©í•´ ë™ê¸° í˜¸ì¶œ
            ctx = "\n\n".join([d.page_content for d in docs])
            result = retriever.document_chain.invoke({"messages": st.session_state["messages"], "context": ctx})
            st.chat_message("assistant").write(result)
    st.session_state["messages"].append(AIMessage(result)) # AI ë©”ì‹œì§€ ì €ì¥ 
    